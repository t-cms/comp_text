---
title: "Final Project"
author: "Tiasia Saunders"
date: "2025-05-01"
output: html_document
---
In an R Markdown document, compile text from news sources or Reddit, compile it into a dataframe, tokenize it, produce lists of bigrams, examine use of adjectives surrounding your narratives, examine sentiment of the bigrams, use the keyword in context technique to track key narratives, produce one topic model.

Include a link to the source data that you have compiled in your GitHub repository.

Describe a content analysis plan and a draft code book.

Load the appropriate software libraries.

Load the data.

Create ggplot chart showing the distribution of the data over time

Create a ggplot chart showing top 20 bigrams.

Conduct a sentiment analysis by article or by bigram. Determine how sentiment has changed over time. Visualize the sentiment analysis.

Construct a topic model and identify the top six narratives *

Write an essay with your findings, at least 800 words. Add link to essay: 

##load libraries 
```{r}
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Load libraries
library(tidyverse)
library(tidytext)
library(lubridate)
library(stringr)
library(ggplot2)
library(dplyr)
library(googledrive)
library

```


##loading Trump DEI data 


```{r}
googledrive::drive_deauth()
temp_file <- tempfile()
drive_download(as_id("1fexSMTg_wJOpyh_XCuc_3_2CP_FGS_tB"), path = temp_file)

#the file id is in the URL for your trump_dei_final_index.csv. which you get from clicking "Share on the Google Drive version and copying the link: https://drive.google.com/file/d/1fexSMTg_wJOpyh_XCuc_3_2CP_FGS_tB/view?usp=sharing
#https://drive.google.com/file/d/1fexSMTg_wJOpyh_XCuc_3_2CP_FGS_tB/view?usp=sharing
#your file id: "1fexSMTg_wJOpyh_XCuc_3_2CP_FGS_tB"'

# Then import the downloaded file from your hard drive
dei_articles <- rio::import(temp_file, format = "csv") # If you know the file format, specify it explicitly..."csv" or "xlsx", "txt", etc.

```
